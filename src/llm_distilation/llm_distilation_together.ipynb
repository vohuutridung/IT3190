{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:19.841753Z",
     "start_time": "2025-11-22T07:56:19.826067Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from together import Together\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:19.892420Z",
     "start_time": "2025-11-22T07:56:19.852767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL = \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
    "SPLIT_MODEL = \"openai/gpt-oss-20b\"\n",
    "BASE_PROMPT_GENERATE_FILEPATH = \"prompts/generate_split_sentences.txt\"\n",
    "BASE_PROMPT_FILTER_FILEPATH = \"prompts/filter_split_sentences.txt.txt\"\n",
    "\n",
    "INPUT_DATASET = \"vohuutridung/3190-data\"\n",
    "OUTPUT_FILE = \"output/atoss_sft_dataset.txt\"\n",
    "OUTPUT_RAW_FILE = \"output/atoss_raw_dataset.txt\"\n",
    "\n",
    "load_dotenv()\n",
    "client = Together(api_key=os.getenv(\"TOGETHER_API_KEY\"))"
   ],
   "id": "3e757f1347a277e7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:19.921538Z",
     "start_time": "2025-11-22T07:56:19.906224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_generate_prompt(sentence, aspects):\n",
    "    prompt = f\"\"\"\n",
    "You are a sentence splitting expert. You will be provided with a review sentence and a few [aspect, category, sentiment, opinion] quadruplets from that review sentence. Here is the definition of each element in the quadruplet:\n",
    "- The ‘aspect’ refers to a specific feature, attribute, or aspect of a product or service that a user may express an opinion about. The aspect term might be ‘null’ for an implicit aspect.\n",
    "- The ‘opinion’ refers to the sentiment or attitude expressed by a user towards a particular aspect or feature of a product or service. The opinion term might be ‘null’ for an implicit opinion.\n",
    "- The ‘category’ refers to the category that the aspect belongs to (e.g. food quality, restaurant general, etc.).\n",
    "- The ‘sentiment’ refers to the sentiment class of the aspect (e.g. positive, negative, neutral).\n",
    "\n",
    "You need to split the sentence into shorter sentences such that each short sentence contains one aspect term. When splitting, sentences connected by conjunctions must be divided into individual sentences along with their conjunctions. This process must specify the subject in every sentence. This process must retain the existing spellings exactly as in the original sentence. This process must also retain the existing spacings exactly as in the original sentence. If the sentence is too short to split or does not need to be split, use the original sentence as is. No numbering, line breaks, or explanations are needed.\n",
    "\n",
    "ORIGINAL SENTENCE:\n",
    "{sentence}\n",
    "\n",
    "ASPECT TERMS:\n",
    "{aspects}\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def create_filter_prompt(sentence, aspects, candidates, K):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a strict evaluator of Aspect-Term-Oriented Sentence Splitting (ATOSS).\n",
    "\n",
    "Your task:\n",
    "Given:\n",
    "- the ORIGINAL sentence,\n",
    "- ASPECT terms,\n",
    "- 10 CANDIDATE split versions S′ (each S′ is a SINGLE STRING containing several shorter sentences),\n",
    "\n",
    "Select EXACTLY {K} BEST versions that follow the splitting rules as closely as possible.\n",
    "If no version fully satisfies all rules, choose the {K} versions with the FEWEST violations.\n",
    "\n",
    "A valid split version S′ MUST satisfy:\n",
    "\n",
    "RULES:\n",
    "1. S′ must be ONE SINGLE STRING that includes several shorter sentences.\n",
    "2. Each shorter sentence MUST contain EXACTLY ONE aspect term.\n",
    "3. All spellings must match the original EXACTLY (no substitutions).\n",
    "4. Spacing should match the original closely, except for necessary spacing added by sentence boundaries created during splitting.\n",
    "5. No rewriting, no paraphrasing, no synonym replacements.\n",
    "6. No content may be added or removed EXCEPT for a period used strictly to split sentences.\n",
    "7. No reordering of any part of the original sentence.\n",
    "8. Every shorter sentence MUST contain an explicit subject.\n",
    "9. Conjunctions (\"and\", \"or\", \"but\", commas) may appear ONLY if they appear in the original.\n",
    "\n",
    "INVALID candidates should be discarded:\n",
    "- If any sentence has zero aspects or more than one → invalid.\n",
    "- If spelling/spacing changes → invalid.\n",
    "- If subject is missing → invalid.\n",
    "- If content is removed, merged, or reordered → invalid.\n",
    "\n",
    "------------------------------------------\n",
    "### EXAMPLES OF CORRECT S′ FORMAT\n",
    "\n",
    "Correct S′ example:\n",
    "very immature bartender, didnt know how to make specific drinks. service was so slowwwww. the food was not fresh or warm. waitresses were busy flirting with men at the bar and werent very attentive to all the customers .\n",
    "\n",
    "Another valid S′:\n",
    "i swore never to return for a warm beer. i swore never to return for a mediocre meal.\n",
    "\n",
    "------------------------------------------\n",
    "\n",
    "When evaluating violations, inserting a period (.) to create a sentence boundary is considered a MINOR and acceptable modification.\n",
    "OUTPUT REQUIREMENT:\n",
    "- Return EXACTLY {K} valid S′ versions.\n",
    "- Each version on its own line.\n",
    "- NO JSON, NO numbering, NO markdown, NO explanation.\n",
    "\n",
    "ORIGINAL SENTENCE:\n",
    "{sentence}\n",
    "\n",
    "ASPECT TERMS:\n",
    "{aspects}\n",
    "\n",
    "CANDIDATES SPLITS:\n",
    "{json.dumps(candidates, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    return prompt"
   ],
   "id": "f388c5fe28770e12",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:19.954853Z",
     "start_time": "2025-11-22T07:56:19.935337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_splits(sentence, aspects, model):\n",
    "\n",
    "    prompt = create_generate_prompt(sentence, aspects)\n",
    "\n",
    "    versions = []\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=1.0\n",
    "        )\n",
    "\n",
    "        text = response.choices[0].message.content\n",
    "        versions.append(text.strip().replace(\"\\n\", \". \"))\n",
    "\n",
    "    print(\"first_raw_output\", versions)\n",
    "    if len(versions) != 10:\n",
    "        print(f\"WARNING: Gemini did not return 10 versions, only {len(versions)} versions\")\n",
    "        print(\"Versions: \", versions)\n",
    "        return versions\n",
    "\n",
    "    return versions"
   ],
   "id": "30547eb75160b545",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:19.988855Z",
     "start_time": "2025-11-22T07:56:19.966753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_split(sentence, aspects, candidates, model, K=2):\n",
    "\n",
    "    prompt = create_filter_prompt(sentence, aspects, candidates, K)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    print(\"Selection response:\", response)\n",
    "    print(\"Selection text: \", text)\n",
    "    selections = [line.strip() for line in text.split(\"\\n\") if line.strip() != \"\"]\n",
    "\n",
    "    if len(selections) != K:\n",
    "        print(f\"WARNING: Gemini did not return {K} selections:\", len(selections))\n",
    "        print(\"Selections: \", selections)\n",
    "        return selections\n",
    "\n",
    "    print(\"Selections: \", selections)\n",
    "    return selections"
   ],
   "id": "1a82657281ae3ba1",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:20.040284Z",
     "start_time": "2025-11-22T07:56:20.003709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "unicode_pattern = re.compile(r'\\\\u[0-9a-zA-Z]{4}')\n",
    "\n",
    "def safe_decode(s: str):\n",
    "    if not unicode_pattern.search(s):\n",
    "        return s\n",
    "\n",
    "    try:\n",
    "        return s.encode('utf-8').decode('unicode_escape')\n",
    "    except:\n",
    "        return s"
   ],
   "id": "9a9ce30d0e7d7182",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:20.081774Z",
     "start_time": "2025-11-22T07:56:20.054927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_dataset(start, end, output, output_raw):\n",
    "\n",
    "    ds = load_dataset(INPUT_DATASET, split=\"train\")\n",
    "    len_ds = len(ds)\n",
    "    count_process = 0\n",
    "\n",
    "    fout_raw = open(output_raw, \"a\", encoding=\"utf-8\")\n",
    "    fout = open(output, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "    # batch = ds[start:end]\n",
    "    batch = ds.select(range(start, end))\n",
    "\n",
    "    for row in batch:\n",
    "\n",
    "        if count_process == 2:\n",
    "            break\n",
    "\n",
    "        if count_process == 200:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "        count_process += 1\n",
    "        print(\"count:\", count_process)\n",
    "\n",
    "        sentence = row[\"text\"]\n",
    "        aspects = row[\"labels\"]\n",
    "\n",
    "        # Step 1: generate 10 s'\n",
    "        candidates = generate_splits(sentence, aspects, MODEL)\n",
    "        if not candidates:\n",
    "            print(f\"This {sentence} cant be processed in generate_splits function\")\n",
    "            continue\n",
    "        for s_raw_out in candidates:\n",
    "            s_raw_out = safe_decode(s_raw_out)\n",
    "            fout_raw.write(sentence + \"####\" + s_raw_out + \"\\n\")\n",
    "            fout_raw.flush()\n",
    "\n",
    "\n",
    "        # Step 2: Select K s'\n",
    "        best = filter_split(sentence, aspects, candidates, SPLIT_MODEL, 2)\n",
    "        if not best:\n",
    "            print(f\"This {sentence} cant be processed in filter_split function\")\n",
    "            continue\n",
    "\n",
    "        # Step 3: Export\n",
    "        for s_output in best:\n",
    "            # print(\"Output 1: \", s_output)\n",
    "            s_output = safe_decode(s_output)\n",
    "            # print(\"Output 2: \", s_output)\n",
    "            fout.write(sentence + \"####\" + s_output + \"\\n\")\n",
    "            fout.flush()\n",
    "\n",
    "        end_time = time.time()\n",
    "        process_time = end_time - start_time\n",
    "        print(f\"process_time: {process_time}\")\n",
    "\n",
    "        if count_process % 100 == 0:\n",
    "            print(f\"Processed {count_process}/{len_ds} sentences\")\n",
    "\n",
    "\n",
    "    fout.close()\n",
    "    fout_raw.close()\n",
    "    print(\"Process successfully\")\n"
   ],
   "id": "9a5178fdfd536273",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:56:50.344403Z",
     "start_time": "2025-11-22T07:56:20.094177Z"
    }
   },
   "cell_type": "code",
   "source": "build_dataset(0, 200, OUTPUT_FILE, OUTPUT_RAW_FILE)",
   "id": "d10216820263f587",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1\n",
      "first_raw_output ['Mới mua cách đây gần một tháng. Tôi nghĩ rằng mọi thứ đều rất tốt nhưng pin của em xài mới đây đã bị chai 1 phần trăm rồi :((( . . becomes . . Mới mua cách đây gần một tháng. Tôi nghĩ rằng mọi thứ đều rất tốt . Tôi cũng thấy pin của em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Mọi thứ đều rất tốt. Nhưng pin em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Tôi nghĩ mọi thứ đều rất tốt nhưng pin của em xài mới đây đã bị chai 1 phần trăm rồi :((( . . becomes . . Mới mua cách đây gần một tháng. Tôi nghĩ mọi thứ đều rất tốt . Tôi cũng thấy pin của em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Tôi thấy mọi thứ đều rất tốt. Tôi thấy pin của em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Mọi thứ đều rất tốt. Nhưng pin em xài mới đây đã bị chai 1 phần trăm rồi :(((']\n",
      "WARNING: Gemini did not return 10 versions, only 5 versions\n",
      "Versions:  ['Mới mua cách đây gần một tháng. Tôi nghĩ rằng mọi thứ đều rất tốt nhưng pin của em xài mới đây đã bị chai 1 phần trăm rồi :((( . . becomes . . Mới mua cách đây gần một tháng. Tôi nghĩ rằng mọi thứ đều rất tốt . Tôi cũng thấy pin của em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Mọi thứ đều rất tốt. Nhưng pin em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Tôi nghĩ mọi thứ đều rất tốt nhưng pin của em xài mới đây đã bị chai 1 phần trăm rồi :((( . . becomes . . Mới mua cách đây gần một tháng. Tôi nghĩ mọi thứ đều rất tốt . Tôi cũng thấy pin của em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Tôi thấy mọi thứ đều rất tốt. Tôi thấy pin của em xài mới đây đã bị chai 1 phần trăm rồi :(((', 'Mới mua cách đây gần một tháng. Mọi thứ đều rất tốt. Nhưng pin em xài mới đây đã bị chai 1 phần trăm rồi :(((']\n",
      "Selection response: id='oLFomh7-6Ng1vN-9a26dee3f82185c1' object=<ObjectType.ChatCompletion: 'chat.completion'> created=1763798197 model='openai/gpt-oss-20b' choices=[ChatCompletionChoicesData(index=0, logprobs=None, seed=None, finish_reason=<FinishReason.StopSequence: 'stop'>, message=ChatCompletionMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((\\nMới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((', tool_calls=[], reasoning='We need to evaluate candidate splits. Original sentence: \"Mới mua cách đây gần một tháng. Mọi thứ đều rất tốt nhưng pin em xài mới đây đã bị chai 1 phần trăm rồi :((( \"\\n\\nAspect terms: first aspect: [\\'Mọi thứ\\', \\'TỔNG_QUAN\\', \\'TÍCH_CỰC\\', \\'đều rất tốt\\'] meaning aspect phrase \"Mọi thứ đều rất tốt\". second aspect: [\\'pin\\', \\'PIN\\', \\'TIÊU_CỰC\\', \\'bị chai 1 phần trăm rồi\\'] meaning phrase \"pin em xài mới đây đã bị chai 1 phần trăm rồi\". Actually original second part: \"pin em xài mới đây đã bị chai 1 phần trăm rồi\". So each sentence must contain exactly one aspect term. Also must have explicit subject. In Vietnamese, subject could be \"Mọi thứ\" or \"pin em\". But \"pin em\" is not a subject? \"pin em\" is object? The phrase \"pin em xài mới đây đã bị chai 1 phần trăm rồi\" subject is \"pin em\" maybe? Actually \"pin em\" is subject? The sentence: \"pin em xài mới đây đã bị chai 1 phần trăm rồi\". The subject is \"pin em\". So each sentence must contain subject. So first sentence: \"Mọi thứ đều rất tốt\" subject \"Mọi thứ\". Good. Second sentence: \"pin em xài mới đây đã bị chai 1 phần trăm rồi\" subject \"pin em\". Good.\\n\\nAlso must keep original punctuation and spacing. Original has period after first sentence. Then second sentence ends with space and emoticon. The emoticon is \":((( \". There\\'s a space after emoticon? Original: \"pin em xài mới đây đã bị chai 1 phần trăm rồi :((( \". There\\'s a space before emoticon? Actually original: \"pin em xài mới đây đã bị chai 1 phần trăm rồi :((( \". So there is a space before emoticon. After emoticon, space? It shows a space after emoticon. So we need to preserve that.\\n\\nNow evaluate candidates.\\n\\nCandidate 1: \\n\"Mới mua cách đây gần một tháng. Tôi nghĩ rõ ràng mđi thêu rát tột nhưng pin cưa em xái mới đây đã bị chai 1 phần trăm rối :((( . . becomes . . Mới mua cách đây một tháng. Tôi nghĩ rõ ràng mđi thêu rát tột . Tôi cúng thấy pin cưa em xái mới đây đã bị chai 1 phần trăm rối :(((\"\\n\\nThis candidate is nonsense, many spelling errors. So invalid.\\n\\nCandidate 2: \\n\"Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((\"\\n\\nSpelling errors: \"Mđi thêu rát tột\" not original. So invalid.\\n\\nCandidate 3: \\n\"Mới mua cách đây gần một tháng. Tôi nghĩ mđi thêu rát tột nhưng pin cưa em xái mới đây đã bị chai 1 phần trăm rối :((( . . becomes . . Mới mua cách đây một tháng. Tôi nghĩ mđi thêu rát tột . Tôi cúng thấy pin cưa em xái mới đây đã bị chai 1 phần trăm rối :(((\"\\n\\nAgain errors.\\n\\nCandidate 4: \\n\"Mới mua cách đây gần một tháng. Tôi thấy mđi thêu rát tột. Tôi thấy pin cưa em xái mới đây đã bị chai 1 phần trăm rối :(((\"\\n\\nErrors.\\n\\nCandidate 5: \\n\"Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((\"\\n\\nSame as 2.\\n\\nThus all candidates have many spelling errors. So none fully satisfy. We need to choose 2 with fewest violations. Let\\'s count violations per candidate.\\n\\nWe need to check each candidate for:\\n\\n- Spelling/spacing changes: any difference from original. Original: \"Mới mua cách đây gần một tháng. Mọi thứ đều rất tốt nhưng pin em xài mới đây đã bị chai 1 phần trăm rồi :((( \"\\n\\nCandidate 1: many changes. So many violations.\\n\\nCandidate 2: \"Mđi thêu rát tột\" vs \"Mọi thứ đều rất tốt\". So many changes. Also missing subject? \"Mđi thêu rát tột\" subject? \"Mđi\" maybe not subject. So invalid.\\n\\nCandidate 3: same.\\n\\nCandidate 4: \"Mđi thêu rát tột\" again.\\n\\nCandidate 5: same.\\n\\nThus all invalid. We need to pick 2 with fewest violations. Let\\'s count approximate number of differences.\\n\\nCandidate 2: differences: \"Mđi thêu rát tột\" vs \"Mọi thứ đều rất tốt\" (4 words changed). Also missing subject? \"Mđi\" maybe not subject. So 1 subject missing. Also emoticon spacing? It has \":(((\" same. So maybe 5 violations.\\n\\nCandidate 5: same as 2. So tie.\\n\\nCandidate 1: many more.\\n\\nCandidate 3: many.\\n\\nCandidate 4: many.\\n\\nThus choose candidate 2 and 5. They are identical. So output those two lines.\\n\\nBut we must output exactly 2 valid S′ versions. They are invalid but we choose them. So output the strings as given.\\n\\nMake sure to output exactly the candidate strings. They include Unicode. Provide them as is.\\n\\nLet\\'s copy candidate 2 string: \"Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((\"\\n\\nCandidate 5 string: \"Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((\"\\n\\nThey are identical. But we need two lines. So output same twice? That might be acceptable. But maybe we should output candidate 2 and 5. They are same. So output twice.\\n\\nLet\\'s ensure no trailing spaces. Provide exactly.\\n\\n'))] prompt=[] usage=UsageData(prompt_tokens=1721, completion_tokens=1427, total_tokens=3148) metadata={'weight_version': 'default'}\n",
      "Selection text:  Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((\n",
      "Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((\n",
      "Selections:  ['Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((', 'Mới mua cách đây gần một tháng. Mđi thêu rát tột. Nhưng pin em xái mới đây đã bị chai 1 phần trăm rối :(((']\n",
      "process_time: 13.997172355651855\n",
      "count: 2\n",
      "first_raw_output ['Cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm vì tôi cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm vì thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn']\n",
      "WARNING: Gemini did not return 10 versions, only 5 versions\n",
      "Versions:  ['Cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm vì tôi cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn', 'Cảm thấy ko hài lòng với sản phẩm vì thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn']\n",
      "Selection response: id='oLFopWP-4YNCb4-9a26df268dfa85c1' object=<ObjectType.ChatCompletion: 'chat.completion'> created=1763798210 model='openai/gpt-oss-20b' choices=[ChatCompletionChoicesData(index=0, logprobs=None, seed=None, finish_reason=<FinishReason.StopSequence: 'stop'>, message=ChatCompletionMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Cảm thấy ko hài lỗng với sản phẩm mẽ dù thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn\\nCảm thấy ko hài lỗng với sản phẩm vè thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn', tool_calls=[], reasoning='We need to evaluate candidate splits. The original sentence: \"Cảm thấy ko hài lòng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng cảm thấy ko ổn\"\\n\\nAspect terms: [[\\'sản phẩm\\', \\'TỔNG_QUAN\\', \\'TIÊU_CỰC\\', \\'ko hài lòng\\']]. So aspect term is \"sản phẩm\" and \"ko hài lòng\"? Actually the list includes multiple? The aspect terms list seems to contain multiple tokens: \\'sản phẩm\\', \\'TỔNG_QUAN\\', \\'TIÊU_CỰC\\', \\'ko hài lòng\\'. But the rule: each shorter sentence must contain exactly one aspect term. So we need to split into sentences each containing exactly one of these aspect terms. But the aspect terms are not necessarily contiguous? The aspect term \"ko hài lòng\" is a phrase. The original sentence contains \"ko hài lòng\" and \"sản phẩm\". So we have two aspect terms present. So we need to split into two sentences: one containing \"ko hài lòng\" and one containing \"sản phẩm\". Each sentence must have explicit subject. The original subject is \"Cảm thấy\" (I feel). So each sentence must start with \"Cảm thấy\" or include subject. But we cannot reorder. We can split by inserting period. The candidate splits are all same string? Let\\'s examine candidates:\\n\\n1. \"Cảm thấy ko hài lỗng với sản phẩm mặc dù thuộc vào dòng cùng cao giá nhưng cảm thấy ko ổn\" (typo: lỗng vs lỗng? Actually original \"hài lòng\" but candidate has \"hài lỗng\" maybe mis-typo). Let\\'s check each candidate.\\n\\nCandidate 1: \"C\\\\u1ea3m th\\\\u1ea5y ko h\\\\u00e0i l\\\\u00f2ng v\\\\u1edbi s\\\\u1ea3n ph\\\\u1ea9m m\\\\u1eb7c d\\\\u00f9 thu\\\\u1ed9c v\\\\u00e0o d\\\\u00f2ng c\\\\u00f9ng cao gi\\\\u00e1 nh\\\\u01b0ng c\\\\u1ea3m th\\\\u1ea5y ko \\\\u1ed5n\"\\n\\nThis is the original sentence but with \"hài lỗng\" maybe? Actually \"h\\\\u00e0i l\\\\u00f2ng\" is \"hài lỗng\" (typo). So spelling changed. So invalid.\\n\\nCandidate 2 same as 1.\\n\\nCandidate 3: \"Cảm thấy ko hài lỗng với sản phẩm vè tời cầm thấy ko hài lỗng với sản phẩm mẽ dù thuộc vào dòng cùng cao giá nhưng tời cầm thấy ko ổn\" This is longer, includes repeated phrase. Also contains \"hài lỗng\" again. Also includes \"tời\" maybe mis-typo. So invalid.\\n\\nCandidate 4: \"Cảm thấy ko hài lỗng với sản phẩm mẽ dù thuộc vào dòng cùng cao giá nhưng tời cầm thấy ko ổn\" again mis-typo.\\n\\nCandidate 5: \"Cảm thấy ko hài lỗng với sản phẩm vè thuộc vào dòng cùng cao giá nhưng tời cầm thấy ko ổn\" again mis-typo.\\n\\nAll candidates have spelling errors: \"hài lỗng\" instead of \"hài lòng\", \"vè\" instead of \"với\", \"tời\" instead of \"tôi\", \"mẽ\" instead of \"mặc\". So all invalid due to spelling changes. Also they don\\'t split into multiple sentences. They are single string with no period. So rule 1: S\\' must be one single string that includes several shorter sentences. So we need at least one period. None have period. So all invalid.\\n\\nThus no candidate fully satisfies all rules. We need to choose 2 versions with fewest violations. We need to count violations per candidate. Let\\'s evaluate each candidate\\'s violations:\\n\\nCandidate 1: Spelling changes: \"hài lỗng\" vs \"hài lòng\" (1), \"mẽ\" vs \"mặc\" (1), \"tời\" vs \"tôi\" (1), \"vè\" vs \"với\" (1). Also no period. So 5 violations. Also maybe missing subject? It has \"Cảm thấy\" as subject. So okay. Also each sentence must contain exactly one aspect term. Since it\\'s one sentence, it contains two aspect terms: \"ko hài lòng\" and \"sản phẩm\". So violation: more than one aspect term. So +1. So total 6 violations.\\n\\nCandidate 2 same as 1: 6 violations.\\n\\nCandidate 3: Let\\'s parse: \"Cảm thấy ko hài lỗng với sản phẩm vè tời cầm thấy ko hài lỗng với sản phẩm mẽ dù thuộc vào dòng cùng cao giá nhưng tời cầm thấy ko ổn\". This has many errors: \"hài lỗng\" (2 times) (2), \"vè\" (1), \"tời\" (2 times) (2), \"mẽ\" (1). Also no period. Also contains multiple aspect terms: \"ko hài lỗng\" appears twice, \"sản phẩm\" appears twice. So many violations. So maybe 10+.\\n\\nCandidate 4: \"Cảm thấy ko hài lỗng với sản phẩm mẽ dù thuộc vào dòng cùng cao giá nhưng tời cầm thấy ko ổn\". Errors: \"hài lỗng\" (1), \"mẽ\" (1), \"tời\" (1). No period. Contains two aspect terms. So 4 violations.\\n\\nCandidate 5: \"Cảm thấy ko hài lỗng với sản phẩm vè thuộc vào dòng cùng cao giá nhưng tời cầm thấy ko ổn\". Errors: \"hài lỗng\" (1), \"vè\" (1), \"tời\" (1). No period. Contains two aspect terms. So 4 violations.\\n\\nThus candidates 4 and 5 have 4 violations each. Candidates 1 and 2 have 6. Candidate 3 has many. So best are 4 and 5.\\n\\nBut we need to output exactly 2 valid S\\' versions. But they are invalid. But we must choose the two with fewest violations. So we output candidate 4 and 5 as they have 4 violations each. But we must output them as they are. They are single strings. They don\\'t have period. But rule 1 says must include several shorter sentences. But we can\\'t modify. So they are invalid. But we still output them because we must choose 2 best. So output the two strings.\\n\\nThus final answer: two lines: candidate 4 and candidate 5.\\n\\nLet\\'s ensure we output exactly those strings. They are:\\n\\n\"C\\\\u1ea3m th\\\\u1ea5y ko h\\\\u00e0i l\\\\u00f2ng v\\\\u1edbi s\\\\u1ea3n ph\\\\u1ea9m m\\\\u1eb7c d\\\\u00f9 thu\\\\u1ed9c v\\\\u00e0o d\\\\u00f2ng c\\\\u00f9ng cao gi\\\\u00e1 nh\\\\u01b0ng t\\\\u00f4i c\\\\u1ea3m th\\\\u1ea5y ko \\\\u1ed5n\"\\n\\nand\\n\\n\"C\\\\u1ea3m th\\\\u1ea5y ko h\\\\u00e0i l\\\\u00f2ng v\\\\u1edbi s\\\\u1ea3n ph\\\\u1ea9m v\\\\u00ec thu\\\\u1ed9c v\\\\u00e0o d\\\\u00f2ng c\\\\u00f9ng cao gi\\\\u00e1 nh\\\\u01b0ng t\\\\u00f4i c\\\\u1ea3m th\\\\u1ea5y ko \\\\u1ed5n\"\\n\\nWait candidate 4 string: \"C\\\\u1ea3m th\\\\u1ea5y ko h\\\\u00e0i l\\\\u00f2ng v\\\\u1edbi s\\\\u1ea3n ph\\\\u1ea9m m\\\\u1eb7c d\\\\u00f9 thu\\\\u1ed9c v\\\\u00e0o d\\\\u00f2ng c\\\\u00f9ng cao gi\\\\u00e1 nh\\\\u01b0ng t\\\\u00f4i c\\\\u1ea3m th\\\\u1ea5y ko \\\\u1ed5n\"\\n\\nCandidate 5 string: \"C\\\\u1ea3m th\\\\u1ea5y ko h\\\\u00e0i l\\\\u00f2ng v\\\\u1edbi s\\\\u1ea3n ph\\\\u1ea9m v\\\\u00ec thu\\\\u1ed9c v\\\\u00e0o d\\\\u00f2ng c\\\\u00f9ng cao gi\\\\u00e1 nh\\\\u01b0ng t\\\\u00f4i c\\\\u1ea3m th\\\\u1ea5y ko \\\\u1ed5n\"\\n\\nYes.\\n\\nThus output those two lines.'))] prompt=[] usage=UsageData(prompt_tokens=1211, completion_tokens=2006, total_tokens=3217) metadata={'weight_version': 'default'}\n",
      "Selection text:  Cảm thấy ko hài lỗng với sản phẩm mẽ dù thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn\n",
      "Cảm thấy ko hài lỗng với sản phẩm vè thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn\n",
      "Selections:  ['Cảm thấy ko hài lỗng với sản phẩm mẽ dù thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn', 'Cảm thấy ko hài lỗng với sản phẩm vè thuộc vào dòng cùng cao giá nhưng tôi cảm thấy ko ổn']\n",
      "process_time: 13.515552043914795\n",
      "Process successfully\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T03:11:44.758548Z",
     "start_time": "2025-11-23T03:11:42.063350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "INPUT_DATASET = \"vohuutridung/3190-data\"\n",
    "ds = load_dataset(INPUT_DATASET, split=\"validation\")\n",
    "\n",
    "print(ds[300])\n",
    "# 55"
   ],
   "id": "6ab39ee63136da64",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Invalid key: 300 is out of bounds for size 300",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m INPUT_DATASET \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvohuutridung/3190-data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      3\u001B[0m ds \u001B[38;5;241m=\u001B[39m load_dataset(INPUT_DATASET, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mds\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# 55\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\datasets\\arrow_dataset.py:2876\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2874\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marrow\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpandas\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolars\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   2875\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m Column(\u001B[38;5;28mself\u001B[39m, key)\n\u001B[1;32m-> 2876\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\datasets\\arrow_dataset.py:2857\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2855\u001B[0m format_kwargs \u001B[38;5;241m=\u001B[39m format_kwargs \u001B[38;5;28;01mif\u001B[39;00m format_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[0;32m   2856\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[1;32m-> 2857\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m \u001B[43mquery_table\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2858\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m format_table(\n\u001B[0;32m   2859\u001B[0m     pa_subtable, key, formatter\u001B[38;5;241m=\u001B[39mformatter, format_columns\u001B[38;5;241m=\u001B[39mformat_columns, output_all_columns\u001B[38;5;241m=\u001B[39moutput_all_columns\n\u001B[0;32m   2860\u001B[0m )\n\u001B[0;32m   2861\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\datasets\\formatting\\formatting.py:612\u001B[0m, in \u001B[0;36mquery_table\u001B[1;34m(table, key, indices)\u001B[0m\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    611\u001B[0m     size \u001B[38;5;241m=\u001B[39m indices\u001B[38;5;241m.\u001B[39mnum_rows \u001B[38;5;28;01mif\u001B[39;00m indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m table\u001B[38;5;241m.\u001B[39mnum_rows\n\u001B[1;32m--> 612\u001B[0m     \u001B[43m_check_valid_index_key\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m \u001B[38;5;66;03m# Query the main table\u001B[39;00m\n\u001B[0;32m    614\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\datasets\\formatting\\formatting.py:552\u001B[0m, in \u001B[0;36m_check_valid_index_key\u001B[1;34m(key, size)\u001B[0m\n\u001B[0;32m    550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m    551\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (key \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;241m+\u001B[39m size \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (key \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m size):\n\u001B[1;32m--> 552\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid key: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is out of bounds for size \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    554\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mslice\u001B[39m):\n",
      "\u001B[1;31mIndexError\u001B[0m: Invalid key: 300 is out of bounds for size 300"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

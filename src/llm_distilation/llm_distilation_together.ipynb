{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T12:25:31.606257Z",
     "start_time": "2025-11-18T12:25:31.602278Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from together import Together\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:25:31.643253Z",
     "start_time": "2025-11-18T12:25:31.612902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    "BASE_PROMPT_GENERATE_FILEPATH = \"prompts/generate_split_sentences.txt\"\n",
    "BASE_PROMPT_FILTER_FILEPATH = \"prompts/filter_split_sentences.txt.txt\"\n",
    "\n",
    "INPUT_DATASET = \"vohuutridung/3190-data\"\n",
    "OUTPUT_FILE = \"output/atoss_sft_dataset.jsonl\"\n",
    "\n",
    "load_dotenv()\n",
    "# client = Together(api_key=os.getenv(\"TOGETHER_API_KEY\"))\n",
    "client = Together()"
   ],
   "id": "3e757f1347a277e7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:25:31.659218Z",
     "start_time": "2025-11-18T12:25:31.643253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_splits(sentence, aspects):\n",
    "\n",
    "    with open(BASE_PROMPT_GENERATE_FILEPATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompt_base = f.read()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{prompt_base}\n",
    "\n",
    "ORIGINAL SENTENCE:\n",
    "{sentence}\n",
    "\n",
    "ASPECT TERMS:\n",
    "{aspects}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=1.0\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message[\"content\"]\n",
    "\n",
    "    try:\n",
    "        candidates = json.loads(output)\n",
    "    except Exception:\n",
    "        print(\"Output is not json\")\n",
    "        print(output)\n",
    "        return []\n",
    "\n",
    "    return candidates"
   ],
   "id": "30547eb75160b545",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:25:31.675098Z",
     "start_time": "2025-11-18T12:25:31.659218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_split(sentence, aspects, candidates, K=2):\n",
    "\n",
    "    with open(BASE_PROMPT_FILTER_FILEPATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompt_base = f.read()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{prompt_base}\n",
    "\n",
    "ORIGINAL SENTENCE:\n",
    "{sentence}\n",
    "\n",
    "ASPECT TERMS:\n",
    "{aspects}\n",
    "\n",
    "CANDIDATES SPLITS:\n",
    "{json.dumps(candidates, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message[\"content\"]\n",
    "\n",
    "    try:\n",
    "        filtered = json.loads(output)\n",
    "    except Exception:\n",
    "        print(\"Output is not json\")\n",
    "        print(output)\n",
    "        return []\n",
    "\n",
    "    return filtered[:K]"
   ],
   "id": "1a82657281ae3ba1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:25:31.690838Z",
     "start_time": "2025-11-18T12:25:31.679786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_dataset():\n",
    "\n",
    "    ds = load_dataset(INPUT_DATASET, split=\"train\")\n",
    "    len_ds = len(ds)\n",
    "    count_process = 0\n",
    "\n",
    "    fout = open(OUTPUT_FILE, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    for row in ds:\n",
    "\n",
    "        count_process += 1\n",
    "\n",
    "        sentence = row[\"text\"]\n",
    "        aspects = row[\"labels\"]\n",
    "\n",
    "        # Step 1: generate 10 s'\n",
    "        candidates = generate_splits(sentence, aspects)\n",
    "        if not candidates:\n",
    "            print(f\"This {sentence} cant be processed in generate_splits function\")\n",
    "            continue\n",
    "\n",
    "        # Step 2: Select K s'\n",
    "        best = filter_split(sentence, aspects, candidates)\n",
    "        if not best:\n",
    "            print(f\"This {sentence} cant be processed in filter_split function\")\n",
    "            continue\n",
    "\n",
    "        # Step 3: Export\n",
    "        for s_output in best:\n",
    "            fout.write(\n",
    "                json.dumps(\n",
    "                    {\n",
    "                        \"instruction\": sentence,\n",
    "                        \"output\": s_output,\n",
    "                    },\n",
    "                    ensure_ascii=False,\n",
    "                )\n",
    "                + \"\\n\"\n",
    "            )\n",
    "\n",
    "        if count_process % 100 == 0:\n",
    "            print(f\"Processed {count_process}/{len_ds} sentences\")\n",
    "\n",
    "\n",
    "    fout.close()\n",
    "    print(\"Process successfully\")\n"
   ],
   "id": "9a5178fdfd536273",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:25:36.381633Z",
     "start_time": "2025-11-18T12:25:31.690838Z"
    }
   },
   "cell_type": "code",
   "source": "build_dataset()",
   "id": "d10216820263f587",
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {\"message\": \"Invalid API key provided. You can find your API key at https://api.together.ai/settings/api-keys.\", \"type_\": \"invalid_request_error\", \"code\": \"invalid_api_key\"}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mbuild_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[23], line 17\u001B[0m, in \u001B[0;36mbuild_dataset\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m aspects \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Step 1: generate 10 s'\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m candidates \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_splits\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maspects\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m candidates:\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msentence\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m cant be processed in generate_splits function\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[21], line 16\u001B[0m, in \u001B[0;36mgenerate_splits\u001B[1;34m(sentence, aspects)\u001B[0m\n\u001B[0;32m      4\u001B[0m         prompt_base \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m      6\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;132;01m{\u001B[39;00mprompt_base\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;132;01m{\u001B[39;00maspects\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m---> 16\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\n\u001B[0;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     output \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\together\\resources\\chat\\completions.py:141\u001B[0m, in \u001B[0;36mChatCompletions.create\u001B[1;34m(self, messages, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, presence_penalty, frequency_penalty, min_p, logit_bias, seed, stream, logprobs, echo, n, safety_model, response_format, tools, tool_choice, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m requestor \u001B[38;5;241m=\u001B[39m api_requestor\u001B[38;5;241m.\u001B[39mAPIRequestor(\n\u001B[0;32m    113\u001B[0m     client\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client,\n\u001B[0;32m    114\u001B[0m )\n\u001B[0;32m    116\u001B[0m parameter_payload \u001B[38;5;241m=\u001B[39m ChatCompletionRequest(\n\u001B[0;32m    117\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m    118\u001B[0m     messages\u001B[38;5;241m=\u001B[39mmessages,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    139\u001B[0m )\u001B[38;5;241m.\u001B[39mmodel_dump(exclude_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 141\u001B[0m response, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTogetherRequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPOST\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mchat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameter_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, TogetherResponse)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\together\\abstract\\api_requestor.py:249\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[1;34m(self, options, stream, remaining_retries, request_timeout)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    233\u001B[0m     options: TogetherRequest,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    241\u001B[0m ]:\n\u001B[0;32m    242\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[0;32m    243\u001B[0m         options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m    244\u001B[0m         remaining_retries\u001B[38;5;241m=\u001B[39mremaining_retries \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretries,\n\u001B[0;32m    245\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[0;32m    246\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[0;32m    247\u001B[0m     )\n\u001B[1;32m--> 249\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\together\\abstract\\api_requestor.py:650\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[1;34m(self, result, stream)\u001B[0m\n\u001B[0;32m    647\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    648\u001B[0m     content \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mcontent\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    649\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m--> 650\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    651\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    652\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    653\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    654\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    655\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    657\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\intro_ml_3.10\\lib\\site-packages\\together\\abstract\\api_requestor.py:748\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[1;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[0;32m    746\u001B[0m \u001B[38;5;66;03m# Handle streaming errors\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[1;32m--> 748\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(resp, rcode, stream_error\u001B[38;5;241m=\u001B[39mstream)\n\u001B[0;32m    749\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[1;31mAuthenticationError\u001B[0m: Error code: 401 - {\"message\": \"Invalid API key provided. You can find your API key at https://api.together.ai/settings/api-keys.\", \"type_\": \"invalid_request_error\", \"code\": \"invalid_api_key\"}"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
